{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVS1iRIkGaa5"
   },
   "source": [
    "Create Synthetic Data-Set for ML Model\n",
    "\n",
    "Motiavtion:\n",
    "  1- To check the behavior of Algorithm,\n",
    "  2- To understand and visulize how diffrent data distributions look,\n",
    "  3- What are the optimal strategy for various data distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLjsL3k0Gaa_"
   },
   "source": [
    "1. Create Dataset with perfectly known performance of the ml models:\n",
    "\n",
    "   Binary-Classification, classes are 50:50: \n",
    "   Features: Gaussian distribution, classes: 50%-0; 50%-1\n",
    "   Every model has a true predicting power of 50% accuracy\n",
    "   Model score = True predicting power?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGrxVRNmGabA"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import tqdm.contrib.itertools\n",
    "import sklearn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import loguniform,uniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WChDeFAHGabD"
   },
   "outputs": [],
   "source": [
    "#Create Helper function for data creation and visulization in 2D\n",
    "def create_dataset(Features,dataset_size,data_seed):\n",
    "    np.random.seed(seed=data_seed)\n",
    "    X = np.random.random((dataset_size,Features))\n",
    "    y = np.empty(dataset_size,int)\n",
    "    y[::2] = 0\n",
    "    y[1::2] = 1\n",
    "    return X,y\n",
    "\n",
    "def visualize_2d(X,y,title=\"2D Data \",figsize=(8,8)):\n",
    "    if X.shape[1]>2:\n",
    "        pca = PCA(n_components=2)\n",
    "        X = pca.fit_transform(X)\n",
    "    else:\n",
    "        if type(X)==pd.DataFrame:\n",
    "            X=X.values\n",
    "    # Plot 2D-Data\n",
    "    f, (ax1) = plt.subplots(nrows=1, ncols=1,figsize=figsize)\n",
    "    sns.scatterplot(X[:,0],X[:,1],hue=y,ax=ax1)\n",
    "    ax1.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    X1 = pd.DataFrame(X,columns=['x','y'])\n",
    "    y1 = pd.Series(y)\n",
    "    # Plot 1st Component\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(25,8))\n",
    "    sns.distplot(X1[y1==1]['x'],bins=50,label=\"True Class\",ax=ax1)\n",
    "    sns.distplot(X1[y1==0]['x'],bins=50,label=\"False Class\",ax=ax1)\n",
    "    ax1.set_xlabel(\"1st Dim\")\n",
    "    ax1.legend()\n",
    "    # Plot 1st Component\n",
    "    sns.distplot(X1[y1==1]['y'],bins=50,label=\"True Class\",ax=ax2)\n",
    "    sns.distplot(X1[y1==0]['y'],bins=50,label=\"False Class\",ax=ax2)\n",
    "    ax2.set_xlabel(\"2nd Dim\")\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "vPDjN0ynGabE",
    "outputId": "4c57c2cd-af4f-4ce9-fc88-784907b08d66"
   },
   "outputs": [],
   "source": [
    "# Construct dataset\n",
    "X,y = create_dataset(dataset_size=100,Features=2,data_seed=1)\n",
    "visualize_2d(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation Strategie\n",
    "\n",
    "cv_inner=2\n",
    "\n",
    "def nested_cv(X,y,hyper_opt,model,cv_inner=cv_inner):\n",
    "    outer_split = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "    score_list = []\n",
    "    for train_index, test_index in outer_split.split(X):\n",
    "        X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "        best_model = hyper_opt(X_train, y_train, model, cv_inner)\n",
    "        score = sklearn.metrics.accuracy_score(y_test,best_model.predict(X_test))\n",
    "        score_list.append(score)\n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "def simple_cv(X,y,hyper_opt,model,cv_inner=cv_inner):\n",
    "    best_model = hyper_opt(X,y,model,cv_inner)\n",
    "    return best_model.best_score_\n",
    "\n",
    "test_size = 0.2\n",
    "train_val_split = ShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "\n",
    "def hold_out(X,y,hyper_opt,model,cv_inner=train_val_split):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size,random_state=0)\n",
    "    best_model = hyper_opt(X_train, y_train, model, cv_inner)\n",
    "    score = sklearn.metrics.accuracy_score(y_test,best_model.predict(X_test))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper_Opt\n",
    "\n",
    "random_iterations=100\n",
    "\n",
    "def random_hyper_opt(X,y,model,cv_inner, random_iterations=random_iterations):\n",
    "    estimator = model()\n",
    "    rand_opt = RandomizedSearchCV(estimator=estimator,scoring='accuracy', param_distributions=rand_grid_model[model.__name__], \n",
    "                                  cv=cv_inner, n_iter=random_iterations)\n",
    "    rand_opt.fit(X,y)\n",
    "    return rand_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models\n",
    "\n",
    "def desicion_tree():\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    return model\n",
    "\n",
    "def logistic_regression():\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitons Search Space\n",
    "## Data set\n",
    "Features = [5]\n",
    "Dataset_size = [50,100,250,500,1000,5000,10000]\n",
    "data_seed = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "## Evaluation Strategie\n",
    "evaluation_strategie = [nested_cv,simple_cv,hold_out]\n",
    "\n",
    "## Hyper_Opt\n",
    "hyper_opt = [random_hyper_opt]\n",
    "\n",
    "### Random_Opt\n",
    "rand_grid_model = {'desicion_tree' : {'min_samples_split': list(np.linspace(0.001, 0.1,11)),\n",
    "                                      'min_samples_leaf':list(np.linspace(0.001, 0.1,11)),\n",
    "                                      'max_depth':list(range(2,7))},\n",
    "                   \n",
    "                   'logistic_regression' : {\"C\": loguniform(0.01, 100)}\n",
    "                  }\n",
    "\n",
    "## Models\n",
    "models = [desicion_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    iterations = tqdm.contrib.itertools.product(Features,Dataset_size,evaluation_strategie,hyper_opt,models,data_seed)\n",
    "\n",
    "    df_results = pd.DataFrame(columns=['Features','Dataset_size','Data_seed',\n",
    "                                       'Performance_Eval','Hyperopt','Model',\n",
    "                                       'Performance'])\n",
    "    for iteration in iterations:\n",
    "        X,y = create_dataset(Features = iteration[0], dataset_size = iteration[1], data_seed = iteration[5])\n",
    "        score = iteration[2](X,y,hyper_opt=iteration[3],model=iteration[4])\n",
    "        result = [iteration[0],iteration[1],iteration[5],\n",
    "                  iteration[2].__name__,iteration[3].__name__,iteration[4].__name__,score]\n",
    "        df_results.loc[len(df_results)] = result\n",
    "        df_results.to_csv('results.csv',index=False)\n",
    "\n",
    "    return\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "df = pd.read_csv('results.csv',index_col=False)\n",
    "\n",
    "Model_plot = 'desicion_tree'\n",
    "hyper_opt_plot = 'random_hyper_opt'\n",
    "plotet_lines = ['hold_out','nested_cv','simple_cv']\n",
    "Features_plot = 5\n",
    "\n",
    "dict_plot = {'hold_out': {'colour':'red','filler_colour':'rgba(255,0,0,0.1)'},\n",
    "            'nested_cv': {'colour':'blue','filler_colour':'rgba(0,0,255,0.1)'},\n",
    "            'simple_cv': {'colour':'green','filler_colour':'rgba(0,255,0,0.1)'}           \n",
    "            }\n",
    "x_axis = 'Dataset_size'\n",
    "hue = 'Performance_Eval'\n",
    "\n",
    "\n",
    "df_plot = df.loc[(df['Model']==Model_plot)&(df['Hyperopt']==hyper_opt_plot)&(df['Features']==Features_plot)]\n",
    "\n",
    "df_plot = df_plot.groupby(['Features','Dataset_size','Performance_Eval','Hyperopt','Model'],as_index = False)\n",
    "df_plot = df_plot.agg({'Performance':['mean', 'std','min','max']})\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "for name, dict_ in dict_plot.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name= name,\n",
    "            x=df_plot[x_axis].loc[df_plot[hue]==name],\n",
    "            y=df_plot['Performance']['mean'].loc[df_plot[hue]==name],\n",
    "            mode='lines',\n",
    "            line=dict(color=dict_['colour']),\n",
    "        ))\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=name + ' upper bound',\n",
    "            x=df_plot[x_axis].loc[df_plot[hue]==name],\n",
    "            y=(df_plot['Performance']['min']).loc[df_plot[hue]==name],\n",
    "            mode='lines',\n",
    "            marker=dict(color=dict_['colour']),\n",
    "            line=dict(width=1, dash='dash'),\n",
    "            showlegend=False\n",
    "        ))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            name=name + ' lower bound',\n",
    "            x=df_plot[x_axis].loc[df_plot[hue]==name],\n",
    "            y=(df_plot['Performance']['max']).loc[df_plot[hue]==name],\n",
    "            marker=dict(color=dict_['colour']),\n",
    "            line=dict(width=1, dash='dash'),\n",
    "            mode='lines',\n",
    "            fillcolor=dict_['filler_colour'],\n",
    "            fill='tonexty',\n",
    "            showlegend=False\n",
    "        ))\n",
    "    \n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MLModel.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
